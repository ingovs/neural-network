# Neural Network From Scratch
This repository contains a simple implementation of a neural network built entirely from scratch using only Python and fundamental libraries (like NumPy). The goal of this project is learning and understanding the core concepts behind neural networks—such as forward propagation, backpropagation, gradient descent, and activation functions—without relying on high-level machine learning frameworks.

It is meant as an educational project to deepen my understanding of how neural networks work under the hood.

After this, I'm planning on implementing Monte Carlo Tree Search (MCTS) and Convolutional Neural Network (CNN), with the ultimate goal of implementing AlphaZero Chess (Google DeepMind) from scratch.

Roadmap:
Micrograd -> MLP -> MCTS -> CNN -> AlphaZero Chess

My reference to this NN was Andrej Karpathy's Zero to Hero video (thanks for the class, Andrej!): https://www.youtube.com/watch?v=VMj-3S1tku0&list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ
